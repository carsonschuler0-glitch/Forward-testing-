# Telegram Bot Configuration
TELEGRAM_BOT_TOKEN=your_telegram_bot_token_here
TELEGRAM_CHAT_ID=your_telegram_chat_id_here

# Polymarket Configuration
POLYMARKET_API_URL=https://clob.polymarket.com
POLYMARKET_GAMMA_API=https://gamma-api.polymarket.com

# Monitoring Configuration
POLL_INTERVAL_MS=10000
MIN_TRADE_SIZE_USD=100
LIQUIDITY_THRESHOLD_PERCENT=10
TOP_TRADER_PERCENTILE=5
MIN_TRADER_VOLUME_USD=1000

# Database (optional - for trader history tracking)
# If not set, will use in-memory storage
# DB_PATH=./data/traders.db

# ============================================================
# ARBITRAGE BOT CONFIGURATION
# ============================================================

# Execution Mode: 'simulation' or 'live'
ARB_EXECUTION_MODE=simulation

# Thresholds
ARB_MIN_PROFIT_THRESHOLD=0.5
ARB_MIN_CONFIDENCE=0.7
ARB_DETECTION_INTERVAL_MS=10000

# Simulation Settings
ARB_SIM_STARTING_BALANCE=10000
ARB_SIM_BASE_SLIPPAGE_BPS=10
ARB_SIM_LIQUIDITY_IMPACT=0.5

# Live Execution (USE WITH CAUTION - requires wallet)
# ARB_PRIVATE_KEY=your_private_key_here
ARB_CHAIN_ID=137
ARB_MAX_SLIPPAGE_BPS=50

# Risk Management
ARB_MAX_POSITION_SIZE_USD=1000
ARB_MAX_TOTAL_EXPOSURE_USD=5000
ARB_MAX_DAILY_LOSS_USD=500
ARB_MIN_LIQUIDITY_USD=5000
ARB_TRADE_COOLDOWN_MS=5000

# Market Matching
ARB_MIN_SIMILARITY_SCORE=0.7

# Detection Toggles
ARB_ENABLE_MULTI_OUTCOME=true
ARB_ENABLE_NEGRISK=true
ARB_ENABLE_CROSS_MARKET=true
ARB_ENABLE_RELATED_MARKET=true
ARB_ENABLE_SEMANTIC_DEPENDENCY=false

# Telegram Alerts for Arbitrage (uses existing TELEGRAM_BOT_TOKEN)
ARB_TELEGRAM_ENABLED=true

# ============================================================
# LLM CONFIGURATION (for semantic dependency detection)
# ============================================================

# LLM Provider: 'openai', 'deepseek', or 'ollama'
LLM_PROVIDER=deepseek

# API Key (not needed for local Ollama)
LLM_API_KEY=your_llm_api_key_here

# Base URL (customize for different providers)
# DeepSeek: https://api.deepseek.com/v1
# OpenAI: https://api.openai.com/v1
# Ollama: http://localhost:11434/v1
LLM_BASE_URL=https://api.deepseek.com/v1

# Model name
# DeepSeek: deepseek-chat, deepseek-reasoner
# OpenAI: gpt-4o-mini, gpt-4o
# Ollama: llama3, mistral, etc.
LLM_MODEL=deepseek-chat

# Generation parameters
LLM_MAX_TOKENS=1024
LLM_TEMPERATURE=0.1

# Rate limiting (requests per minute)
LLM_RATE_LIMIT=30

# Cache settings
LLM_CACHE_TTL_MS=3600000
LLM_CACHE_SIZE=10000

# Enable/disable LLM-based detection
LLM_ENABLED=false
LLM_MIN_CONFIDENCE=0.75
